---
title: "Bayesian Hierarchical Weibull Regression"
subtitle: JQT paper with 200 drivers - Model 3
author: "Miao Cai^[Department of Epidemiology and Biostatistics, Saint Louis University. Email address [miao.cai@slu.edu](miao.cai@slu.edu)]"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: readable
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    code_folding: hide
    highlight: tango
  pdf_document:
    number_sections: yes
link-citations: yes
linkcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = T, cache = T)
```

# Weibull Distribution

The probability density function of a Weibull distribution is
\[
f(t) = \begin{cases}
\frac{\kappa}{\theta}\Big(\frac{t}{\theta}\Big)^{\kappa - 1}e^{(t/\theta)^\kappa}, & t>8 \\
0, & t\leq 0
\end{cases}
\]

Then the survival function is:
\[
S(t) = P(T > t) = 1 - P(T \leq t) = e^{-(t/\theta)^\kappa}
\]

The hazard function is the first order derivative of the survival function:
\[
h(t) = \frac{dS(t)}{dt} = \frac{\kappa}{\theta}\Big(\frac{t}{\theta}\Big)^{\kappa - 1}
\]




# Weibull regression

We assume $Y_{i, d(i), s(i)}$ is the time until the first critical event from the start of a trip, then we have
\begin{align*}
Y_{i, d(i), s(i)} & \sim \text{WEIBULL}(\kappa, \theta) \\
\theta & = \exp(\beta_{0, d(i)} + \beta_{1, d(i)} \cdot \text{CT}_i + \mathbf{\xi} \cdot \mathbf{W} + \mathbf{\nu} \cdot \mathbf{D_i})
\end{align*}

Where the $\theta$ is the scale parameter and $\kappa$ is the shape parameter. When $\kappa > 1$, the hazard of having critical event is increasing as cumulative driving time gets longer, which indicates fatigued driving. When $\kappa = 1$, the Weibull distribution becomes an exponential distribution with constant hazard $\frac{1}{\theta}$, which indicates no fatigue. When $0 < \kappa < 1$, the hazard of having critical events is decreasing with longer cumulative driving time, which indicates anti-fatigue, or burn-in.

# Censoring in Stan

In essense, Stan is evaluating a log probability function (probability density function or probability mass function) for a given set of parameters; this function returns the log density of the posterior up to an additive constant.

There are two ways of dealing with censoring in stan:

- estimating censored values
- integrating out censored values

Estimating censored values in Stan is to treat these censored values as missing data with some constraint (lower bound, upper bound or interval). These censored values will be declared as parameters with constraints, and then estimated or imputed by their distribution. However, this way is not feasible when the censored data are huge, which leads to a huge amount parameters to be estimated.

The other way to deal with censored data is integrating out the censored values. Let's assume the data are right censored, which is common in survival data analysis. The probability of each censored datum can be calculated as:

\[
P(t > C) = \int_C^\infty f(t|\kappa, \theta)dt = 1 - \Lambda(C|\kappa, \theta)
\]


Where $f(t|\kappa, \theta)$ and $\Lambda(t|\kappa, \theta)$ are the probability density function and cumulative density function of Weibull distribution.


The log of total probability of $N$ censored points is:
\begin{equation}\label{ltotalpdf}
\log \prod_{i = 1}^N P(t_i > C_i) = \sum_{i = 1}^N\log\Big(1 - \Lambda(C_i|\kappa, \theta)\Big)
\end{equation}

Stan provides `<distribution>_lccdf` as the log of complementary CDF for built-in distributions, so `weibull_lccdf` is the log of complementary CDF of weibull distribution. The Equation \@ref(ltotalpdf) can be expressed as the following function in Stan:

\begin{align*}
\log \prod_{i = 1}^N P(t_i > C_i) & = \sum_{i = 1}^N \texttt{weibull_lccdf}(C_i|\kappa, \theta)\\

\end{align*}

When it is translated into Stan `model` block, it becomes:

```
for (i in 1:N){
  target += weibull_lccdf(censored_time[i] | kappa, theta)
}
```




# Examples

This is the Mice example of Weibull regression, originally provided in WinBUGS example models, and then provided by [the STAN forum](https://discourse.mc-stan.org/t/weibull-regression/6098). 

## Data

```{r data}
rm(list=ls(all=TRUE))
require(rstan)
require(shinystan)

N_uncensored <- 65L
N_censored <- 15L
M <- 4
group_uncensored <-
c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4)
group_censored <-
c(1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4)
t_uncensored <-
c(12, 17, 21, 25, 11, 26, 27, 30, 13, 12, 21, 20, 23, 25, 23, 
29, 35, 31, 36, 32, 27, 23, 12, 18, 38, 29, 30, 32, 25, 30, 37, 
27, 22, 26, 28, 19, 15, 12, 35, 35, 10, 22, 18, 12, 31, 24, 37, 
29, 27, 18, 22, 13, 18, 29, 28, 16, 22, 26, 19, 17, 28, 26, 12, 
17, 26)
censor_time <-
c(40, 40, 40, 40, 40, 40, 40, 40, 10, 24, 40, 40, 20, 29, 10)

dataList = list(
  N_censored = N_censored , 
  N_uncensored = N_uncensored , # BUGS does not treat 1-column mat as vector
  M = M ,
  group_uncensored = group_uncensored ,
  group_censored = group_censored,
  censor_time = censor_time,
  t_uncensored = t_uncensored
)
```

## Official code provide by the Stan team

```{r OfficialCode, results='hide'}
mice1 = "
data {
  int<lower=0> N_uncensored;
  int<lower=0> N_censored;
  int<lower=0> M;
  int<lower=1,upper=M> group_uncensored[N_uncensored];
  int<lower=1,upper=M> group_censored[N_censored];
  real<lower=0> censor_time[N_censored];
  real<lower=0> t_uncensored[N_uncensored];
}

parameters {
  real<lower=0> r;
  real beta[M];
  real<lower=1> t2_censored[N_censored]; // t_censored / censor_time 
}

model {
  r ~ exponential(0.001);
  beta ~ normal(0, 100);
  for (n in 1:N_uncensored) {
    t_uncensored[n] ~ weibull(r, exp(-beta[group_uncensored[n]] / r));
  }
  for (n in 1:N_censored) {
    t2_censored[n] ~ weibull(r, exp(-beta[group_censored[n]] / r) / censor_time[n]);
  }
}

generated quantities {
  real median[M];
  real pos_control;
  real test_sub;
  real veh_control;
  
  for (m in 1:M)
    median[m] <- pow(log(2) * exp(-beta[m]), 1/r);
  
  veh_control <- beta[2] - beta[1];
  test_sub    <- beta[3] - beta[1];
  pos_control <- beta[4] - beta[1];
}
" 

miceHMM1 <- stan(model_code=mice1, data=dataList, seed = 47306, chains=4,  
                    iter=5000, 
                    warmup=2000 ) # init=initsChains
```

```{r result1}
knitr::kable(summary(miceHMM1), 
             digits = 2,
             caption = 'Summary statistics by the official Stan team')
```


## Code by Miao

```{r MiaoCode, results='hide'}
miao = "
data {
  int<lower=0> N_uncensored;
  int<lower=0> N_censored;
  int<lower=0> M;
  int<lower=1,upper=M> group_uncensored[N_uncensored];
  int<lower=1,upper=M> group_censored[N_censored];
  real<lower=0> censor_time[N_censored];
  real<lower=0> t_uncensored[N_uncensored];
}

parameters{
  real<lower=0> r;
  vector[M] beta;
}

model{
  for (i in 1:N_uncensored){
    t_uncensored[i] ~ weibull(r, exp(-beta[group_uncensored[i]] / r));
  }
  for (j in 1:N_censored){
    target += weibull_lccdf(censor_time[j]|r, exp(-beta[group_censored[j]] / r));
  }
  
  r ~ gamma(1, 1);
  beta ~ normal(0, 100);
  
}

generated quantities {
  real median[M];
  real pos_control;
  real test_sub;
  real veh_control;
  
  for (m in 1:M)
    median[m] <- pow(log(2) * exp(-beta[m]), 1/r);
  
  veh_control <- beta[2] - beta[1];
  test_sub    <- beta[3] - beta[1];
  pos_control <- beta[4] - beta[1];
}
"


miceHMM <- stan(model_code=miao, data=dataList, seed = 47306, chains=4,  
                    iter=5000, 
                    warmup=2000 ) # init=initsChains
```

```{r result2}
knitr::kable(summary(miceHMM),
             digits = 2,
             caption = 'Summary statistics by Miao')
```

